{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf79517",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division\n",
    "from BashColors import C\n",
    "from TarfileFunctions import *\n",
    "\n",
    "import os\n",
    "from os.path import exists, join\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '4'\n",
    "\n",
    "contentPath = os.getcwd()\n",
    "checkpointPath= join(contentPath, 'Checkpoints')\n",
    "genPath = join(contentPath, 'DataGenerator')\n",
    "if not exists(genPath):\n",
    "    tff.extractTarfiles('DataGenerator.tar.gz')\n",
    "testPath = join(contentPath, 'images')\n",
    "if not exists(testPath):\n",
    "    tff.extractTarfiles('images.tar.gz')\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "import tensorflow as tf\n",
    "print(f'tensorflow: {C.BIBlue}{tf.__version__}{C.ColorOff}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08b8953",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='loss', min_delta=0, patience=2, verbose=1,\n",
    "    mode='auto', baseline=None, restore_best_weights=True,\n",
    "    # print('\\n',\n",
    ")\n",
    "\n",
    "checkpoints = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath = checkpointPath,\n",
    "    monitor='loss', verbose=1, save_best_only=True,\n",
    "    save_weights_only=False, mode='auto', save_freq='epoch',\n",
    "    options=None\n",
    ")\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5307f8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE=(224, 224)\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "train_ds = image_dataset_from_directory(\n",
    "    genPath,\n",
    "    color_mode='rgb',\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=456,\n",
    "    image_size=(224, 224),\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE)\n",
    "print()\n",
    "\n",
    "validation_ds = image_dataset_from_directory(\n",
    "    genPath,\n",
    "    color_mode='rgb',\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=456,\n",
    "    image_size=(224, 224),\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE)\n",
    "print()\n",
    "\n",
    "test_ds = image_dataset_from_directory(\n",
    "    testPath,\n",
    "    color_mode='rgb',\n",
    "    image_size=(224, 224),\n",
    "    shuffle=False,\n",
    "    batch_size = BATCH_SIZE)\n",
    "# clear_output()\n",
    "\n",
    "TRAIN_STEPS = len(train_ds) // BATCH_SIZE\n",
    "print('\\nTRAIN_STEPS:', TRAIN_STEPS)\n",
    "VAL_STEPS = len(validation_ds) // BATCH_SIZE\n",
    "print('VAL_STEPS:', VAL_STEPS)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ea88c60d",
   "metadata": {},
   "source": [
    "Args\n",
    "input_shape\n",
    "Optional shape tuple, only to be specified if include_top is False (otherwise the input shape has to be (224, 224, 3) (with channels_last data format) or (3, 224, 224) (with channels_first data format). It should have exactly 3 inputs channels, and width and height should be no smaller than 32. E.g. (200, 200, 3) would be one valid value. Default to None. input_shape will be ignored if the input_tensor is provided.\n",
    "\n",
    "alpha\n",
    "Controls the width of the network. This is known as the width multiplier in the MobileNet paper. - If alpha < 1.0, proportionally decreases the number of filters in each layer. - If alpha > 1.0, proportionally increases the number of filters in each layer. - If alpha = 1, default number of filters from the paper are used at each layer. Default to 1.0.\n",
    "\n",
    "depth_multiplier\n",
    "Depth multiplier for depthwise convolution. This is called the resolution multiplier in the MobileNet paper. Default to 1.0.\n",
    "\n",
    "dropout\n",
    "Dropout rate. Default to 0.001.\n",
    "\n",
    "include_top\n",
    "Boolean, whether to include the fully-connected layer at the top of the network. Default to True.\n",
    "\n",
    "weights\n",
    "One of None (random initialization), 'imagenet' (pre-training on ImageNet), or the path to the weights file to be loaded. Default to imagenet.\n",
    "\n",
    "input_tensor\n",
    "Optional Keras tensor (i.e. output of layers.Input()) to use as image input for the model. input_tensor is useful for sharing inputs between multiple different networks. Default to None.\n",
    "\n",
    "pooling\n",
    "Optional pooling mode for feature extraction when include_top is False.\n",
    "None (default) means that the output of the model will be the 4D tensor output of the last convolutional block.\n",
    "avg means that global average pooling will be applied to the output of the last convolutional block, and thus the output of the model will be a 2D tensor.\n",
    "max means that global max pooling will be applied.\n",
    "\n",
    "classes\n",
    "Optional number of classes to classify images into, only to be specified if include_top is True, and if no weights argument is specified. Defaults to 1000.\n",
    "classifier_activation\n",
    "A str or callable. The activation function to use on the \"top\" layer. Ignored unless include_top=True. Set classifier_activation=None to return the logits of the \"top\" layer. When loading pretrained weights, classifier_activation can only be None or \"softmax\".\n",
    "**kwargs\n",
    "For backwards compatibility only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394e9cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (224, 224, 3)\n",
    "DROPOUT = 0.001  # Default to 0.001\n",
    "ALPHA = 2.0  # Default to 1.0\n",
    "\n",
    "model  =  tf.keras.applications.mobilenet.MobileNet(   input_shape = INPUT_SHAPE, alpha = ALPHA, depth_multiplier = 16,\n",
    "    dropout = DROPOUT, include_top = False, weights = None,\n",
    "    input_tensor = None, pooling = None, classes = 1000,\n",
    "    classifier_activation = 'softmax'\n",
    ")\n",
    "\n",
    "print()\n",
    "\n",
    "print()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45040efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "layerCount=0\n",
    "for layer in model.layers:\n",
    "    layerCount+=1\n",
    "    print(f'{layerCount}. {C.BIBlue}{layer}{C.ColorOff} parameters:{layer.count_params()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
