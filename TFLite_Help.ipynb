{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e41bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division\n",
    "from IPython.display import clear_output\n",
    "from BashColors import C\n",
    "import tflite_model_maker\n",
    "import tflite_model_maker as tmm\n",
    "import os\n",
    "from os.path import *\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "print(f'tflite: {C.BIBlue}{tmm.__version__}{C.ColorOff}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2481dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tflite_model_maker\n",
    "tflite_model_maker.image_classifier.ImageClassifier(\n",
    "    model_spec, index_to_label, shuffle=True,\n",
    "    hparams=hub_lib.get_default_hparams(),\n",
    "    use_augmentation=False, representative_data=None\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0e945c76",
   "metadata": {},
   "source": [
    "Args\n",
    "model_spec\n",
    "Specification for the model.\n",
    "\n",
    "index_to_label\n",
    "A list that map from index to label class name.\n",
    "\n",
    "shuffle\n",
    "Whether the data should be shuffled.\n",
    "\n",
    "hparams\n",
    "A namedtuple of hyperparameters. This function expects .dropout_rate: The fraction of the input units to drop, used in dropout layer. .do_fine_tuning: If true, the Hub module is trained together with the classification layer on top.\n",
    "        \n",
    "use_augmentation\n",
    "Use data augmentation for preprocessing.\n",
    "\n",
    "representative_data\n",
    "Representative dataset for full integer quantization. Used when converting the keras model to the TFLite model with full integer quantization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e0932f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@classmethod\n",
    "create(\n",
    "    train_data, model_spec='efficientnet_lite0', validation_data=None,\n",
    "    batch_size=None, epochs=None, steps_per_epoch=None, train_whole_model=None,\n",
    "    dropout_rate=None, learning_rate=None, momentum=None, shuffle=False,\n",
    "    use_augmentation=False, use_hub_library=True, warmup_steps=None, model_dir=None,\n",
    "    do_train=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5471f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Loads data and retrains the model based on data for image classification.\n",
    "\n",
    "Args\n",
    "train_data\n",
    "Training data.\n",
    "\n",
    "model_spec\n",
    "Specification for the model.\n",
    "\n",
    "validation_data\n",
    "Validation data. If None, skips validation process.\n",
    "\n",
    "batch_size\n",
    "Number of samples per training step. If use_hub_library is False, it represents the base learning rate when train batch size is 256 and it's linear to the batch size.\n",
    "\n",
    "epochs\n",
    "Number of epochs for training.\n",
    "\n",
    "steps_per_epoch\n",
    "Integer or None. Total number of steps (batches of samples) before declaring one epoch finished and starting the next epoch. If steps_per_epoch is None, the epoch will run until the input dataset is exhausted.\n",
    "\n",
    "train_whole_model\n",
    "If true, the Hub module is trained together with the classification layer on top. Otherwise, only train the top classification layer.\n",
    "\n",
    "dropout_rate\n",
    "The rate for dropout.\n",
    "\n",
    "learning_rate\n",
    "Base learning rate when train batch size is 256. Linear to the batch size.\n",
    "\n",
    "momentum\n",
    "a Python float forwarded to the optimizer. Only used when use_hub_library is True.\n",
    "\n",
    "shuffle\n",
    "Whether the data should be shuffled.\n",
    "\n",
    "use_augmentation\n",
    "Use data augmentation for preprocessing.\n",
    "\n",
    "use_hub_library\n",
    "Use make_image_classifier_lib from tensorflow hub to retrain the model.\n",
    "\n",
    "warmup_steps\n",
    "Number of warmup steps for warmup schedule on learning rate. If None, the default warmup_steps is used which is the total training steps in two epochs. Only used when use_hub_library is False.\n",
    "\n",
    "model_dir\n",
    "The location of the model checkpoint files. Only used when use_hub_library is False.\n",
    "\n",
    "do_train\n",
    "Whether to run training.\n",
    "Returns\n",
    "An instance based on ImageClassifier.\n",
    "create_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51035fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_model(\n",
    "    hparams=None, with_loss_and_metrics=False\n",
    ")  # Creates the classifier model for retraining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ef5baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_serving_model\n",
    "create_serving_model() #Returns underlining Keras model for serving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b53302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate\n",
    "evaluate(\n",
    "    data, batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "547d8d17",
   "metadata": {},
   "source": [
    "Evaluates the model.\n",
    "Args\n",
    "\n",
    "data\n",
    "Data to be evaluated.\n",
    "\n",
    "batch_size\n",
    "Number of samples per evaluation step.\n",
    "\n",
    "Returns\n",
    "The loss value and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d603b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_tflite\n",
    "evaluate_tflite(\n",
    "    tflite_filepath, data, postprocess_fn=None\n",
    ") # Evaluates the tflite model."
   ]
  },
  {
   "cell_type": "raw",
   "id": "71101c31",
   "metadata": {},
   "source": [
    "Args\n",
    "tflite_filepath\n",
    "File path to the TFLite model.\n",
    "data\n",
    "Data to be evaluated.\n",
    "postprocess_fn\n",
    "Postprocessing function that will be applied to the output of lite_runner.run before calculating the probabilities.\n",
    "Returns\n",
    "The evaluation result of TFLite model - accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8ee050",
   "metadata": {},
   "outputs": [],
   "source": [
    "export(\n",
    "    export_dir, tflite_filename='model.tflite',\n",
    "    label_filename='labels.txt', vocab_filename='vocab.txt',\n",
    "    saved_model_filename='saved_model', tfjs_folder_name='tfjs',\n",
    "    export_format=None, **kwargs\n",
    ") # Converts the retrained model based on export_format."
   ]
  },
  {
   "cell_type": "raw",
   "id": "c74473d5",
   "metadata": {},
   "source": [
    "Args\n",
    "export_dir\n",
    "The directory to save exported files.\n",
    "\n",
    "tflite_filename\n",
    "File name to save tflite model. The full export path is {export_dir}/{tflite_filename}.\n",
    "\n",
    "label_filename\n",
    "File name to save labels. The full export path is {export_dir}/{label_filename}.\n",
    "\n",
    "vocab_filename\n",
    "File name to save vocabulary. The full export path is {export_dir}/{vocab_filename}.\n",
    "\n",
    "saved_model_filename\n",
    "Path to SavedModel or H5 file to save the model. \n",
    "The full export path is {export_dir}/{saved_model_filename}/{saved_model.pb|assets|variables}\n",
    "\n",
    "tfjs_folder_name\n",
    "Folder name to save tfjs model.\n",
    "The full export path is {export_dir}/{tfjs_folder_name}.\n",
    "\n",
    "export_format\n",
    "List of export format that could be saved_model, tflite, label, vocab.\n",
    "\n",
    "**kwargs\n",
    "Other parameters like quantized_config for TFLITE model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b09ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_top_k(\n",
    "    data, k=1, batch_size=32\n",
    ") # tflite_model_maker.image_classifier.ImageClassifier(\n",
    "    model_spec, index_to_label, shuffle=True, hparams=hub_lib.get_default_hparams(),\n",
    "    use_augmentation=False, representative_data=None\n",
    ")\n",
    "Args\n",
    "model_spec\n",
    "Specification for the model.\n",
    "index_to_label\n",
    "A list that map from index to label class name.\n",
    "shuffle\n",
    "Whether the data should be shuffled.\n",
    "hparams\n",
    "A namedtuple of hyperparameters. This function expects .dropout_rate: The fraction of the input units to drop, used in dropout layer. .do_fine_tuning: If true, the Hub module is trained together with the classification layer on top.\n",
    "use_augmentation\n",
    "Use data augmentation for preprocessing.\n",
    "representative_data\n",
    "Representative dataset for full integer quantization. Used when converting the keras model to the TFLite model with full integer quantization.\n",
    "Methods\n",
    "\n",
    "create\n",
    "\n",
    "View source\n",
    "\n",
    "\n",
    "@classmethod\n",
    "create(\n",
    "    train_data, model_spec='efficientnet_lite0', validation_data=None,\n",
    "    batch_size=None, epochs=None, steps_per_epoch=None, train_whole_model=None,\n",
    "    dropout_rate=None, learning_rate=None, momentum=None, shuffle=False,\n",
    "    use_augmentation=False, use_hub_library=True, warmup_steps=None, model_dir=None,\n",
    "    do_train=True\n",
    ")\n",
    "Loads data and retrains the model based on data for image classification.\n",
    "\n",
    "Args\n",
    "train_data\n",
    "Training data.\n",
    "model_spec\n",
    "Specification for the model.\n",
    "validation_data\n",
    "Validation data. If None, skips validation process.\n",
    "batch_size\n",
    "Number of samples per training step. If use_hub_library is False, it represents the base learning rate when train batch size is 256 and it's linear to the batch size.\n",
    "epochs\n",
    "Number of epochs for training.\n",
    "steps_per_epoch\n",
    "Integer or None. Total number of steps (batches of samples) before declaring one epoch finished and starting the next epoch. If steps_per_epoch is None, the epoch will run until the input dataset is exhausted.\n",
    "train_whole_model\n",
    "If true, the Hub module is trained together with the classification layer on top. Otherwise, only train the top classification layer.\n",
    "dropout_rate\n",
    "The rate for dropout.\n",
    "learning_rate\n",
    "Base learning rate when train batch size is 256. Linear to the batch size.\n",
    "momentum\n",
    "a Python float forwarded to the optimizer. Only used when use_hub_library is True.\n",
    "shuffle\n",
    "Whether the data should be shuffled.\n",
    "use_augmentation\n",
    "Use data augmentation for preprocessing.\n",
    "use_hub_library\n",
    "Use make_image_classifier_lib from tensorflow hub to retrain the model.\n",
    "warmup_steps\n",
    "Number of warmup steps for warmup schedule on learning rate. If None, the default warmup_steps is used which is the total training steps in two epochs. Only used when use_hub_library is False.\n",
    "model_dir\n",
    "The location of the model checkpoint files. Only used when use_hub_library is False.\n",
    "do_train\n",
    "Whether to run training.\n",
    "Returns\n",
    "An instance based on ImageClassifier.\n",
    "create_model\n",
    "\n",
    "View source\n",
    "\n",
    "\n",
    "create_model(\n",
    "    hparams=None, with_loss_and_metrics=False\n",
    ")\n",
    "Creates the classifier model for retraining.\n",
    "\n",
    "create_serving_model\n",
    "\n",
    "View source\n",
    "\n",
    "\n",
    "create_serving_model()\n",
    "Returns the underlining Keras model for serving.\n",
    "\n",
    "evaluate\n",
    "\n",
    "View source\n",
    "\n",
    "\n",
    "evaluate(\n",
    "    data, batch_size=32\n",
    ")\n",
    "Evaluates the model.\n",
    "\n",
    "Args\n",
    "data\n",
    "Data to be evaluated.\n",
    "batch_size\n",
    "Number of samples per evaluation step.\n",
    "Returns\n",
    "The loss value and accuracy.\n",
    "evaluate_tflite\n",
    "\n",
    "View source\n",
    "\n",
    "\n",
    "evaluate_tflite(\n",
    "    tflite_filepath, data, postprocess_fn=None\n",
    ")\n",
    "Evaluates the tflite model.\n",
    "\n",
    "Args\n",
    "tflite_filepath\n",
    "File path to the TFLite model.\n",
    "data\n",
    "Data to be evaluated.\n",
    "postprocess_fn\n",
    "Postprocessing function that will be applied to the output of lite_runner.run before calculating the probabilities.\n",
    "Returns\n",
    "The evaluation result of TFLite model - accuracy.\n",
    "export\n",
    "\n",
    "View source\n",
    "\n",
    "\n",
    "export(\n",
    "    export_dir, tflite_filename='model.tflite',\n",
    "    label_filename='labels.txt', vocab_filename='vocab.txt',\n",
    "    saved_model_filename='saved_model', tfjs_folder_name='tfjs',\n",
    "    export_format=None, **kwargs\n",
    ")\n",
    "Converts the retrained model based on export_format.\n",
    "\n",
    "Args\n",
    "export_dir\n",
    "The directory to save exported files.\n",
    "tflite_filename\n",
    "File name to save tflite model. The full export path is {export_dir}/{tflite_filename}.\n",
    "label_filename\n",
    "File name to save labels. The full export path is {export_dir}/{label_filename}.\n",
    "vocab_filename\n",
    "File name to save vocabulary. The full export path is {export_dir}/{vocab_filename}.\n",
    "saved_model_filename\n",
    "Path to SavedModel or H5 file to save the model. The full export path is {export_dir}/{saved_model_filename}/{saved_model.pb|assets|variables}.\n",
    "tfjs_folder_name\n",
    "Folder name to save tfjs model. The full export path is {export_dir}/{tfjs_folder_name}.\n",
    "export_format\n",
    "List of export format that could be saved_model, tflite, label, vocab.\n",
    "**kwargs\n",
    "Other parameters like quantized_config for TFLITE model.\n",
    "predict_top_k\n",
    "\n",
    "View source\n",
    "\n",
    "\n",
    "predict_top_k(\n",
    "    data, k=1, batch_size=32\n",
    ")\n",
    "Predicts the top-k predictions.\n",
    "\n",
    "Args\n",
    "data\n",
    "Data to be evaluated. Either an instance of DataLoader or just raw data entries such TF tensor or numpy array.\n",
    "k\n",
    "Number of top results to be predicted.\n",
    "batch_size\n",
    "Number of samples per evaluation step.\n",
    "Returns\n",
    "top k results. Each one is (label, probability).\n",
    "summary\n",
    "\n",
    "View source\n",
    "\n",
    "\n",
    "summary()\n",
    "train\n",
    "\n",
    "View source\n",
    "\n",
    "\n",
    "train(\n",
    "    train_data, validation_data=None, hparams=None, steps_per_epoch=None\n",
    ")\n",
    "Feeds the training data for training.\n",
    "\n",
    "Args\n",
    "train_data\n",
    "Training data.\n",
    "validation_data\n",
    "Validation data. If None, skips validation process.\n",
    "hparams\n",
    "An instance of hub_lib.HParams or train_image_classifier_lib.HParams. Anamedtuple of hyperparameters.\n",
    "steps_per_epoch\n",
    "Integer or None. Total number of steps (batches of samples) before declaring one epoch finished and starting the next epoch. If 'steps_per_epoch' is None, the epoch will run until the input dataset is exhausted.\n",
    "Returns\n",
    "The tf.keras.callbacks.History object returned by tf.keras.Model.fit*().\n",
    "Class Variables\n",
    "ALLOWED_EXPORT_FORMAT\n",
    "(<ExportFormat.TFLITE: 'TFLITE'>, <ExportFormat.LABEL: 'LABEL'>, <ExportFormat.SAVED_MODEL: 'SAVED_MODEL'>, <ExportFormat.TFJS: 'TFJS'>)\n",
    "DEFAULT_EXPORT_FORMAT\n",
    "(<ExportFormat.TFLITE: 'TFLITE'>, <ExportFormat.LABEL: 'LABEL'>)Predicts the top-k predictions.\n",
    "\n",
    "Args\n",
    "data\n",
    "Data to be evaluated. Either an instance of DataLoader or just raw data entries such TF tensor or numpy array.\n",
    "k\n",
    "Number of top results to be predicted.\n",
    "batch_size\n",
    "Number of samples per evaluation step.\n",
    "Returns\n",
    "top k results. Each one is (label, probability).\n",
    "summary\n",
    "\n",
    "View source\n",
    "\n",
    "\n",
    "summary()\n",
    "train\n",
    "\n",
    "View source\n",
    "\n",
    "\n",
    "train(\n",
    "    train_data, validation_data=None, hparams=None, steps_per_epoch=None\n",
    ")\n",
    "Feeds the training data for training.\n",
    "\n",
    "Args\n",
    "train_data\n",
    "Training data.\n",
    "validation_data\n",
    "Validation data. If None, skips validation process.\n",
    "hparams\n",
    "An instance of hub_lib.HParams or train_image_classifier_lib.HParams. Anamedtuple of hyperparameters.\n",
    "steps_per_epoch\n",
    "Integer or None. Total number of steps (batches of samples) before declaring one epoch finished and starting the next epoch. If 'steps_per_epoch' is None, the epoch will run until the input dataset is exhausted.\n",
    "Returns\n",
    "The tf.keras.callbacks.History object returned by tf.keras.Model.fit*().\n",
    "Class Variables\n",
    "ALLOWED_EXPORT_FORMAT\n",
    "(<ExportFormat.TFLITE: 'TFLITE'>, <ExportFormat.LABEL: 'LABEL'>, <ExportFormat.SAVED_MODEL: 'SAVED_MODEL'>, <ExportFormat.TFJS: 'TFJS'>)\n",
    "DEFAULT_EXPORT_FORMAT\n",
    "(<ExportFormat.TFLITE: 'TFLITE'>, <ExportFormat.LABEL: 'LABEL'>)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
