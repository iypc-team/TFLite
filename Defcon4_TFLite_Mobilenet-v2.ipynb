{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a936adce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/lite/tutorials/model_maker_image_classification\n",
    "from __future__ import absolute_import, division\n",
    "from BashColors import C\n",
    "from CV2_Utils_2 import *\n",
    "from TarfileFunctions import *\n",
    "\n",
    "\n",
    "from time import perf_counter, sleep\n",
    "import itertools, os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '4'\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "assert tf.__version__.startswith('2')\n",
    "\n",
    "from tflite_model_maker import model_spec\n",
    "from tflite_model_maker import image_classifier\n",
    "from tflite_model_maker.config import ExportFormat\n",
    "from tflite_model_maker.config import QuantizationConfig\n",
    "from tflite_model_maker.image_classifier import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "contentPath=os.getcwd()\n",
    "image_path=os.path.join(contentPath, 'images')\n",
    "generatorPath=os.path.join(contentPath, 'DataGenerator')\n",
    "generatorPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb56256",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataLoader.from_folder(generatorPath)\n",
    "train_ds, val_ds = data.split(0.8)\n",
    "print()\n",
    "# print('\\nnum_classes:', train_ds.num_classes)\n",
    "# print('class names', train_ds.index_to_label)\n",
    "\n",
    "train_size = train_ds.gen_dataset()\n",
    "item = train_size.cardinality()\n",
    "print(item)\n",
    "S = train_size.cardinality() // 8\n",
    "\n",
    "val_size = val_ds.gen_dataset()\n",
    "print(val_size.cardinality())\n",
    "V = val_size.cardinality() // 8\n",
    "print(S, V)\n",
    "# print('cardinality: ',genDs.cardinality().numpy(),'\\n')\n",
    "# for item in genDs:\n",
    "    # print(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38beaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs='''\n",
    "IMAGE_SIZE = (224,224,3)\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "from tensorflow.keras.layers import RandomFlip, RandomTranslation\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "train_de, val_ds = image_dataset_from_directory(\n",
    "    directory=generatorPath, shuffle=True, seed=456,\n",
    "    validation_split=0.2, subset='training', label_mo\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11e5edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(subset):\n",
    "    return image_dataset_from_directory(\n",
    "        generatorPath,\n",
    "        shuffle = False,\n",
    "        validation_split = 0.2,\n",
    "        subset = subset,\n",
    "        label_mode = \"categorical\",\n",
    "        seed = 456, # Seed provided when using validation_split \n",
    "        # and shuffle  =  True.\n",
    "        # A fixed seed is used so that the validation set is stable \n",
    "        # across runs.\n",
    "        image_size = (224,224),\n",
    "        batch_size = 8)\n",
    "\n",
    "train_ds  =  build_dataset(\"training\")\n",
    "class_names  =  tuple(train_ds.class_names)\n",
    "train_size  =  train_ds.cardinality().numpy()\n",
    "train_ds  =  train_ds.unbatch().batch(BATCH_SIZE)\n",
    "train_ds  =  train_ds.repeat()\n",
    "\n",
    "normalization_layer  =  tf.keras.layers.Rescaling(1. / 255)\n",
    "preprocessing_model  =  tf.keras.Sequential([normalization_layer])\n",
    "do_data_augmentation  =  True\n",
    "if do_data_augmentation:\n",
    "    preprocessing_model.add(tf.keras.layers.RandomRotation(40))\n",
    "    \n",
    "    preprocessing_model.add(RandomTranslation(0, 0.05))\n",
    "    preprocessing_model.add(RandomTranslation(0.05, 0))\n",
    "    preprocessing_model.add(RandomTranslation(0, 0.1))\n",
    "    preprocessing_model.add(RandomTranslation(0.1, 0))\n",
    "    preprocessing_model.add(RandomTranslation(0, 0.2))\n",
    "    preprocessing_model.add(RandomTranslation(0.2, 0))\n",
    "    # Like the old tf.keras.preprocessing.image.ImageDataGenerator(),\n",
    "    # image sizes fixed when reading, then a random zoom is applied.\n",
    "    # If training inputs larger than image_size, one could also use,\n",
    "    # RandomCrop with a batch size of 1 and rebatch later.\n",
    "    \n",
    "    preprocessing_model.add(tf.keras.layers.RandomZoom(0.2, 0.2))\n",
    "    preprocessing_model.add(tf.keras.layers.RandomZoom(-0.1, -0.1))\n",
    "    \n",
    "    preprocessing_model.add(RandomFlip(mode = \"horizontal\"))\n",
    "    preprocessing_model.add(RandomFlip(mode = \"vertical\"))\n",
    "    \n",
    "train_ds  =  train_ds.map(lambda images, labels:\n",
    "                        (preprocessing_model(images), labels))\n",
    "\n",
    "val_ds  =  build_dataset(\"validation\")\n",
    "valid_size  =  val_ds.cardinality().numpy()\n",
    "val_ds  =  val_ds.unbatch().batch(BATCH_SIZE)\n",
    "val_ds  =  val_ds.map(lambda images, labels:\n",
    "                    (normalization_layer(images), labels))\n",
    "# STEPS_PER_EPOCH = train_ds.cardinality().numpy()\n",
    "# VALIDATION_STEPS = val_ds.cardinality(). numpy()\n",
    "# print(STEPS_PER_EPOCH, VALIDATION_STEPS)\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38e3b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "model  =  tflite_model_maker.image_classifier.create(\n",
    "    train_ds, model_spec = 'mobilenet_v2',\n",
    "    validation_data = val_ds, # default\n",
    "    batch_size = None, # default None\n",
    "    epochs = None,  # default None\n",
    "    steps_per_epoch = None,  # default None\n",
    "    train_whole_model = None, # default None\n",
    "    dropout_rate = None,  # default None\n",
    "    learning_rate = None,  # default None\n",
    "    momentum = None, # default None\n",
    "    shuffle = False,\n",
    "    use_augmentation = False, # default False\n",
    "    use_hub_library = True, warmup_steps = None,  # default None\n",
    "    model_dir = None, # default None\n",
    "    do_train = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eee9abe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f8a91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.ALLOWED_EXPORT_FORMAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd135b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fb13e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.export(export_dir='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ba300d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7f25b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = DataLoader.from_folder(image_path, shuffle=False)\n",
    "print('\\n', type(testData), '\\n')\n",
    "# help(DataLoader.from_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13d7624",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, rest_data = data.split(0.5)\n",
    "validation_data, val_ds = rest_data.split(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ab96eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow_examples.lite.model_maker.core.data_util.image_dataloader import ImageClassifierDataLoader\n",
    "def plotDatasetImages(dataset:ImageClassifierDataLoader):\n",
    "    \"\"\" \"\"\"\n",
    "    plt.figure(figsize=(12,12))\n",
    "    for i, (image, label) in enumerate(dataset.gen_dataset().unbatch().take(25)):\n",
    "        plt.subplot(5,5,i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(image.numpy(), cmap=plt.cm.gray)\n",
    "        plt.xlabel(data.index_to_label[label.numpy()])\n",
    "    plt.show()\n",
    "\n",
    "plotDatasetImages(dataset=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040b9ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "module_spec = hub.load_module_spec(\"path/to/module\")\n",
    "height, width = hub.get_expected_image_size(module_spec)\n",
    "images = ...  # A batch of images with shape [batch_size, height, width, 3].\n",
    "module = hub.Module(module_spec)\n",
    "features = module(images)   # A batch with shape [batch_size, num_features]."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
