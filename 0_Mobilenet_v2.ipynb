{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19631263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install tflite-model-maker\n",
    "# %pip install tflite-runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "107a78bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/DataGenerator'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.tensorflow.org/lite/tutorials/model_maker_image_classification\n",
    "from __future__ import absolute_import, division\n",
    "from BashColors import C\n",
    "from CV2_Utils_2 import *\n",
    "from TarfileFunctions import *\n",
    "\n",
    "from time import perf_counter, sleep\n",
    "import itertools, os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '5'\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "assert tf.__version__.startswith('2')\n",
    "\n",
    "from tflite_model_maker import model_spec\n",
    "from tflite_model_maker import image_classifier\n",
    "from tflite_model_maker.config import ExportFormat\n",
    "from tflite_model_maker.config import QuantizationConfig\n",
    "from tflite_model_maker.image_classifier import DataLoader\n",
    "\n",
    "# from tflite_support.metadata_writers import image_classifier\n",
    "# from tflite_support.metadata_writers import writer_utils\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "contentPath=os.getcwd()\n",
    "image_path=os.path.join(contentPath, 'images')\n",
    "generatorPath=os.path.join(contentPath, 'DataGenerator')\n",
    "imagePath=join(contentPath, '3b7d7d8a64.jpg')\n",
    "generatorPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bc7750c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Load image with size: 844, num_label: 3, labels: Enemy, Friendly, Planets.\n",
      "\n",
      "\n",
      "num_classes: 3\n",
      "class names: ['Enemy', 'Friendly', 'Planets']\n",
      "84 10\n"
     ]
    }
   ],
   "source": [
    "data = DataLoader.from_folder(generatorPath)\n",
    "train_ds, restData = data.split(0.8)\n",
    "val_ds, test_ds = restData.split(0.5)\n",
    "print()\n",
    "print('\\nnum_classes:', train_ds.num_classes)\n",
    "print('class names:', train_ds.index_to_label)\n",
    "\n",
    "print(len(train_ds) // 8, len(val_ds)//8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b22b991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Retraining the models...\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hub_keras_layer_v1v2 (HubKe  (None, 1280)             2257984   \n",
      " rasLayerV1V2)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1280)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 3843      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,261,827\n",
      "Trainable params: 3,843\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n",
      "None\n",
      "INFO:tensorflow:Use default resize_bicubic.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Use default resize_bicubic.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Use customized resize method bilinear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Use customized resize method bilinear\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Use customized resize method bilinear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Use customized resize method bilinear\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 59s 1s/step - loss: 0.7088 - accuracy: 0.8735 - val_loss: 0.4777 - val_accuracy: 1.0000\n",
      "completed: 1.0 minutes 31.0 second(s)\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 16\n",
    "EPOCHS = 1\n",
    "DROPOUT_RATE = 0.5\n",
    "LEARNING_RATE = 0.01\n",
    "MOMENTUM = 0.9\n",
    "start=perf_counter()\n",
    "model = image_classifier.create(\n",
    "    train_data = train_ds,\n",
    "    validation_data = val_ds,\n",
    "    model_spec = model_spec.get('mobilenet_v2'),\n",
    "    learning_rate = LEARNING_RATE,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    epochs = EPOCHS,\n",
    "    dropout_rate = DROPOUT_RATE,\n",
    "    use_augmentation = True, # default=False\n",
    "    use_hub_library = True,  # default=True\n",
    "    momentum = MOMENTUM, # Only used when use_hub_library is True\n",
    "    shuffle = False,\n",
    "    train_whole_model = False)\n",
    "\n",
    "finish=perf_counter()\n",
    "cvu.printTime(start, finish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2eb7298a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Use customized resize method bilinear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Use customized resize method bilinear\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 7s 2s/step - loss: 0.4853 - accuracy: 0.9882\n",
      "loss: 0.4852568805217743\taccuracy: 98.82352948188782%\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "# accuracy = round(accuracy, 1)\n",
    "print(f'loss: {loss}\\taccuracy: {accuracy*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "790a89ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp9qzihpod/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp9qzihpod/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Label file is inside the TFLite model with metadata.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Label file is inside the TFLite model with metadata.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving labels in /tmp/tmpmi3n4gcr/labels.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving labels in /tmp/tmpmi3n4gcr/labels.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:TensorFlow Lite model exported successfully: /home/jovyan/Defcon4_mobilenet_v2_ObjectClassifier.tflite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:TensorFlow Lite model exported successfully: /home/jovyan/Defcon4_mobilenet_v2_ObjectClassifier.tflite\n"
     ]
    }
   ],
   "source": [
    "fileName = 'Defcon4_mobilenet_v2_ObjectClassifier.tflite'\n",
    "config = QuantizationConfig.for_float16()\n",
    "\n",
    "model.export(export_dir=contentPath,\n",
    "             tflite_filename=fileName,\n",
    "             quantization_config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d47ab46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method export in module tensorflow_examples.lite.model_maker.core.task.custom_model:\n",
      "\n",
      "export(export_dir, tflite_filename='model.tflite', label_filename='labels.txt', vocab_filename='vocab.txt', saved_model_filename='saved_model', tfjs_folder_name='tfjs', export_format=None, **kwargs) method of tensorflow_examples.lite.model_maker.core.task.image_classifier.ImageClassifier instance\n",
      "    Converts the retrained model based on `export_format`.\n",
      "    \n",
      "    Args:\n",
      "      export_dir: The directory to save exported files.\n",
      "      tflite_filename: File name to save tflite model. The full export path is\n",
      "        {export_dir}/{tflite_filename}.\n",
      "      label_filename: File name to save labels. The full export path is\n",
      "        {export_dir}/{label_filename}.\n",
      "      vocab_filename: File name to save vocabulary. The full export path is\n",
      "        {export_dir}/{vocab_filename}.\n",
      "      saved_model_filename: Path to SavedModel or H5 file to save the model. The\n",
      "        full export path is\n",
      "        {export_dir}/{saved_model_filename}/{saved_model.pb|assets|variables}.\n",
      "      tfjs_folder_name: Folder name to save tfjs model. The full export path is\n",
      "        {export_dir}/{tfjs_folder_name}.\n",
      "      export_format: List of export format that could be saved_model, tflite,\n",
      "        label, vocab.\n",
      "      **kwargs: Other parameters like `quantized_config` for TFLITE model.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(model.export)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03276c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving labels in /home/jovyan/labels.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving labels in /home/jovyan/labels.txt\n"
     ]
    }
   ],
   "source": [
    "model.export(\n",
    "    export_dir=contentPath, export_format=ExportFormat.LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac211ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorflowLiteClassificationModel:\n",
    "    def __init__(self, model_path, labels, image_size=224):\n",
    "        self.interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "        self.interpreter.allocate_tensors()\n",
    "        self._input_details = self.interpreter.get_input_details()\n",
    "        self._output_details = self.interpreter.get_output_details()\n",
    "        self.labels = labels\n",
    "        self.image_size=image_size\n",
    "\n",
    "    def run_from_filepath(self, image_path):\n",
    "        input_data_type = self._input_details[0][\"dtype\"]\n",
    "        image = np.array(Image.open(image_path).resize((self.image_size, self.image_size)), dtype=input_data_type)\n",
    "        if input_data_type == np.float32:\n",
    "            image = image / 255.\n",
    "\n",
    "        if image.shape == (1, 224, 224):\n",
    "            image = np.stack(image*3, axis=0)\n",
    "\n",
    "        return self.run(image)\n",
    "\n",
    "    def run(self, image):\n",
    "        \"\"\"\n",
    "        args:\n",
    "          image: a (1, image_size, image_size, 3) np.array\n",
    "\n",
    "        Returns list of [Label, Probability], of type List<str, float>\n",
    "        \"\"\"\n",
    "\n",
    "        self.interpreter.set_tensor(self._input_details[0][\"index\"], image)\n",
    "        self.interpreter.invoke()\n",
    "        tflite_interpreter_output = self.interpreter.get_tensor(self._output_details[0][\"index\"])\n",
    "        probabilities = np.array(tflite_interpreter_output[0])\n",
    "\n",
    "        # create list of [\"label\", probability], ordered descending probability\n",
    "        label_to_probabilities = []\n",
    "        for i, probability in enumerate(probabilities):\n",
    "            label_to_probabilities.append([self.labels[i], float(probability)])\n",
    "        return sorted(label_to_probabilities, key=lambda element: element[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01c2038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage\n",
    "modelPath='/home/jovyan/Defcon4_mobilenet_v2_ObjectClassifier.tflite'\n",
    "imagePath=join(contentPath, '3b7d7d8a64.jpg')\n",
    "labelsPath=join(contentPath, 'labels.txt')\n",
    "model = TensorflowLiteClassificationModel(\n",
    "    model_path=modelPath, labels=labelsPath)\n",
    "img=cvu.getCV2Image(imagePath)\n",
    "(label, probability) = model.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fb55cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelPath='/home/jovyan/Defcon4_mobilenet_v2_ObjectClassifier.tflite'\n",
    "import tensorflow as tf\n",
    "import tflite_runtime.interpreter as tflite\n",
    "interpreter = tf.lite.Interpreter(model_path=modelPath)\n",
    "\n",
    "interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c456e7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "modelPath='/home/jovyan/Defcon4_mobilenet_v2_ObjectClassifier.tflite'\n",
    "# Load the TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_path=modelPath)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Test the model on random input data.\n",
    "input_shape = input_details[0]['shape']\n",
    "input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "interpreter.invoke()\n",
    "\n",
    "# The function `get_tensor()` returns a copy of the tensor data.\n",
    "# Use `tensor()` in order to get a pointer to the tensor.\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(output_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
