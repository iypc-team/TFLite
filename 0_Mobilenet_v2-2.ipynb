{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107a78bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/lite/tutorials/model_maker_image_classification\n",
    "from __future__ import absolute_import, division\n",
    "from BashColors import C\n",
    "from CV2_Utils_2 import *\n",
    "from TarfileFunctions import *\n",
    "\n",
    "from time import perf_counter, sleep\n",
    "import itertools, json, os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '5'\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "assert tf.__version__.startswith('2')\n",
    "\n",
    "from tflite_model_maker import model_spec\n",
    "from tflite_model_maker import image_classifier\n",
    "from tflite_model_maker.config import ExportFormat\n",
    "from tflite_model_maker.config import QuantizationConfig\n",
    "from tflite_model_maker.image_classifier import DataLoader\n",
    "\n",
    "# from tflite_support.metadata_writers import image_classifier\n",
    "# from tflite_support.metadata_writers import writer_utils\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "contentPath=os.getcwd()\n",
    "image_path=os.path.join(contentPath, 'images')\n",
    "generatorPath=os.path.join(contentPath, 'DataGenerator')\n",
    "imagePath=join(contentPath, '3b7d7d8a64.jpg')\n",
    "\n",
    "initialGlobList:list\n",
    "with open(\"initialGlobList.json\", 'r') as f:\n",
    "    initialGlobList = json.load(f)\n",
    "    \n",
    "def listNewFiles(initial=initialGlobList, delete=False):\n",
    "    currentFilesGlob=glob.glob('**')\n",
    "    if len(initial) == len(currentFilesGlob):\n",
    "        print(f'{C.BIRed}No new files in content.')\n",
    "    for fil in currentFilesGlob:\n",
    "        if not fil in initial:\n",
    "            if isdir(fil):\n",
    "                print(f'{C.BIBlue}{fil}')\n",
    "                if delete:\n",
    "                    shutil.rmtree(fil)\n",
    "            elif isfile(fil):\n",
    "                print(f'{C.ColorOff}{fil}')\n",
    "                if delete:\n",
    "                    os.remove(fil)\n",
    "listNewFiles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc7750c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataLoader.from_folder(generatorPath)\n",
    "train_ds, restData = data.split(0.8)\n",
    "val_ds, test_ds = restData.split(0.5)\n",
    "print()\n",
    "print('\\nnum_classes:', train_ds.num_classes)\n",
    "print('class names:', train_ds.index_to_label)\n",
    "\n",
    "print(len(train_ds) // 8, len(val_ds)//8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b22b991",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "EPOCHS = 1\n",
    "DROPOUT_RATE = 0.2\n",
    "LEARNING_RATE = 0.015\n",
    "MOMENTUM = 0.95\n",
    "\n",
    "start=perf_counter()\n",
    "model = image_classifier.create(\n",
    "    train_data = train_ds,\n",
    "    validation_data = val_ds,\n",
    "    model_spec = model_spec.get('mobilenet_v2'),\n",
    "    learning_rate = LEARNING_RATE,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    epochs = EPOCHS,\n",
    "    dropout_rate = DROPOUT_RATE,\n",
    "    use_augmentation = True, # default=False\n",
    "    use_hub_library = True,  # default=True\n",
    "    momentum = MOMENTUM, # Only used when use_hub_library is True\n",
    "    shuffle = False,\n",
    "    train_whole_model = False)\n",
    "\n",
    "finish=perf_counter()\n",
    "cvu.printTime(start, finish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb7298a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "accuracy = round(accuracy, 4)\n",
    "print(f'loss: {loss}\\taccuracy: {accuracy*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cc692a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard code to convert to a tflite model:\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(path + 'saved_model')\n",
    "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_LATENCY]\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8, tf.lite.OpsSet.TFLITE_BUILTINS]\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e130c3",
   "metadata": {},
   "outputs": [],
   "source": [
    " def testTFLiteModel(thisModelPath, inputImage):\n",
    "    '''thisModelPath: fully qualified path to tflite model.'''\n",
    "    interpreter = tf.lite.Interpreter(model_path=thisModelPath)\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "\n",
    "    interpreter.allocate_tensors()\n",
    "    \n",
    "    input_data = np.expand_dims(new_img, axis=0).astype(np.float32)\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "    interpreter.invoke()\n",
    "help(testTFLiteModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed8ba87",
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = 'Defcon4_mobilenet_v2_Dynamic.tflite'\n",
    "config = QuantizationConfig.for_dynamic(optimizations=)\n",
    "help(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790a89ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.export(export_dir=contentPath,\n",
    "             tflite_filename=fileName,\n",
    "             quantization_config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03276c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.export(\n",
    "    export_dir=contentPath, export_format=ExportFormat.LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac211ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "class TensorflowLiteClassificationModel:\n",
    "    def __init__(self, model_path, labels, image_size=224):\n",
    "        self.interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "        self.interpreter.allocate_tensors()\n",
    "        self._input_details = self.interpreter.get_input_details()\n",
    "        self._output_details = self.interpreter.get_output_details()\n",
    "        self.labels = labels\n",
    "        self.image_size=image_size\n",
    "\n",
    "    def run_from_filepath(self, image_path):\n",
    "        input_data_type = self._input_details[0][\"dtype\"]\n",
    "        image = np.array(Image.open(image_path).resize((self.image_size, self.image_size)), dtype=input_data_type)\n",
    "        if input_data_type == np.float32:\n",
    "            image = image / 255.\n",
    "\n",
    "        if image.shape == (1, 224, 224):\n",
    "            image = np.stack(image*3, axis=0)\n",
    "\n",
    "        return self.run(image)\n",
    "\n",
    "    def run(self, image):\n",
    "        \"\"\"\n",
    "        args:\n",
    "          image: a (1, image_size, image_size, 3) np.array\n",
    "\n",
    "        Returns list of [Label, Probability], of type List<str, float>\n",
    "        \"\"\"\n",
    "\n",
    "        self.interpreter.set_tensor(self._input_details[0][\"index\"], image)\n",
    "        self.interpreter.invoke()\n",
    "        tflite_interpreter_output = self.interpreter.get_tensor(self._output_details[0][\"index\"])\n",
    "        probabilities = np.array(tflite_interpreter_output[0])\n",
    "\n",
    "        # create list of [\"label\", probability], ordered descending probability\n",
    "        label_to_probabilities = []\n",
    "        for i, probability in enumerate(probabilities):\n",
    "            label_to_probabilities.append([self.labels[i], float(probability)])\n",
    "        return sorted(label_to_probabilities, key=lambda element: element[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01c2038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage\n",
    "modelPath='/home/jovyan/Defcon4_mobilenet_v2_ObjectClassifier.tflite'\n",
    "imagePath=join(contentPath, '3b7d7d8a64.jpg')\n",
    "labelsPath=join(contentPath, 'labels.txt')\n",
    "model = TensorflowLiteClassificationModel(\n",
    "    model_path=modelPath, labels=labelsPath)\n",
    "img=cvu.getCV2Image(imagePath)\n",
    "# (label, probability) = model.run_from_filepath(image_path=imagePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fb55cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelPath='/home/jovyan/Defcon4_mobilenet_v2_ObjectClassifier.tflite'\n",
    "import tensorflow as tf\n",
    "import tflite_runtime.interpreter as tflite\n",
    "interpreter = tf.lite.Interpreter(model_path=modelPath)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# help(interpreter.get_tensor)\n",
    "interpreter.get_tensor(tensor_index=177)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4229ed52",
   "metadata": {},
   "outputs": [],
   "source": [
    "length=len(test_ds)\n",
    "def get_label_color(val1, val2):\n",
    "  if val1 == val2:\n",
    "    return 'black'\n",
    "  else:\n",
    "    return 'red'\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.rcParams.update({'font.size': 30})\n",
    "predicts = model.predict_top_k(test_ds)\n",
    "for i, (image, label) in enumerate(test_ds.gen_dataset().unbatch().take(20)):\n",
    "\n",
    "    ax = plt.subplot(5, 4, i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(image.numpy(), cmap=plt.cm.gray) # .gray\n",
    "\n",
    "    predict_label = predicts[i][0][0]\n",
    "    color = get_label_color(predict_label,\n",
    "                          test_ds.index_to_label[label.numpy()])\n",
    "    ax.xaxis.label.set_color(color)\n",
    "    plt.xlabel('Predicted: %s' % predict_label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c456e7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "modelPath='/home/jovyan/Defcon4_mobilenet_v2_ObjectClassifier.tflite'\n",
    "# Load the TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_path=modelPath)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Test the model on random input data.\n",
    "input_shape = input_details[0]['shape']\n",
    "input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "interpreter.invoke()\n",
    "\n",
    "# The function `get_tensor()` returns a copy of the tensor data.\n",
    "# Use `tensor()` in order to get a pointer to the tensor.\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(output_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
