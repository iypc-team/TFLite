{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dcd36f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\u001b[1;94m files in contentPath\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division\n",
    "from IPython.display import clear_output\n",
    "from BashColors import C\n",
    "from TarfileFunctions import *\n",
    "\n",
    "import glob, json, os, sys\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '5'\n",
    "from os.path import *\n",
    "from time import perf_counter, perf_counter_ns\n",
    "\n",
    "contentPath = os.getcwd()\n",
    "genPath = join(contentPath, 'DataGenerator')\n",
    "testPath = join(contentPath, 'images')\n",
    "jsonPath = join(contentPath, 'initialGlobList.json')\n",
    "\n",
    "if not exists(genPath):\n",
    "    tff.extractTarfiles('DataGenerator5.tar.gz')\n",
    "if not exists(testPath):\n",
    "    tff.extractTarfiles('images.tar.gz')\n",
    "\n",
    "from time import perf_counter, sleep\n",
    "import concurrent.futures\n",
    "\n",
    "initialGlobList=glob.glob('**')\n",
    "if not 'initialGlobList.json' in initialGlobList:\n",
    "    initialGlobList.append('initialGlobList.json')\n",
    "\n",
    "with open(\"initialGlobList.json\", 'w') as f:\n",
    "    # indent=2 is not needed but makes the file human-readable\n",
    "    json.dump(initialGlobList, f, indent=2)\n",
    "\n",
    "with open(\"initialGlobList.json\", 'r') as f:\n",
    "    initialGlobList = json.load(f)\n",
    "    fileCount=0\n",
    "    for fil in initialGlobList:\n",
    "        fileCount+=1\n",
    "        # print(fil)\n",
    "print(f'{fileCount}{C.BIBlue} files in contentPath')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79bb7896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "\n",
    "modelPath=join(contentPath, 'Defcon4_fp16.tflite')\n",
    "imagePath=join(contentPath, '3b7d7d8a64.jpg')\n",
    "\n",
    "input_details=list()\n",
    "output_details=list()\n",
    "interpreter=None\n",
    "def loadTFLiteModel(path, imagePath, silent=True):\n",
    "    '''Load the model\\npath:Path to tflite model.\\npath to image.'''\n",
    "    interpreter = tf.lite.Interpreter(model_path = modelPath)\n",
    "    interpreter.allocate_tensors()\n",
    "    # Get input and output tensors.\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    # Load image data with dtype=np.uint8\n",
    "    # The input data's shape should match input_details[0]['shape'], which is\n",
    "    # BATCH_SIZE x HEIGHT (192) x WIDTH (192) x CHANNELS (3)\n",
    "    \n",
    "    image = cv2.imread(imagePath, cv2.IMREAD_COLOR)\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    # print(image.shape)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    # print(image.shape)\n",
    "    \n",
    "    interpreter.set_tensor(input_details[0]['index'], image)\n",
    "    interpreter.invoke()\n",
    "    \n",
    "    if not silent:\n",
    "        print(interpreter)\n",
    "        print(type(input_details))\n",
    "        print(input_details, '\\n')\n",
    "        print(type(output_details))\n",
    "        print(output_details)\n",
    "    \n",
    "    return interpreter\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d440f428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'input_1',\n",
       "  'index': 0,\n",
       "  'shape': array([  1, 224, 224,   3], dtype=int32),\n",
       "  'shape_signature': array([ -1, 224, 224,   3], dtype=int32),\n",
       "  'dtype': numpy.uint8,\n",
       "  'quantization': (0.003921568859368563, 0),\n",
       "  'quantization_parameters': {'scales': array([0.00392157], dtype=float32),\n",
       "   'zero_points': array([0], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter = loadTFLiteModel(\n",
    "    path=modelPath, imagePath=imagePath, silent=True)\n",
    "\n",
    "inputt=interpreter.get_input_details()\n",
    "inputt\n",
    "# print(inputt, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac1711c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs=interpreter.get_output_details()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bee7be94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Identity',\n",
       "  'index': 179,\n",
       "  'shape': array([1, 2], dtype=int32),\n",
       "  'shape_signature': array([-1,  2], dtype=int32),\n",
       "  'dtype': numpy.uint8,\n",
       "  'quantization': (0.00390625, 0),\n",
       "  'quantization_parameters': {'scales': array([0.00390625], dtype=float32),\n",
       "   'zero_points': array([0], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputDict={'name': str}\n",
    "outputDict.update()\n",
    "interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9be89d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (1450479496.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_696/1450479496.py\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    output_dict = {\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# loadTFLiteModel(path=modelPath, imagePath=imagePath)\n",
    "\n",
    "    # The function `get_tensor()` returns a copy of the tensor data.\n",
    "    # Use `tensor()` in order to get a pointer to the tensor.\n",
    "    output_dict = {\n",
    "        'num_detections': int(interpreter.get_tensor(output_details[3][\"index\"])),\n",
    "        'detection_classes': interpreter.get_tensor(output_details[1][\"index\"]).astype(np.uint8),\n",
    "        'detection_boxes' : interpreter.get_tensor(outputs[0][\"index\"]),\n",
    "        'detection_scores' : interpreter.get_tensor(outputs[2][\"index\"])\n",
    "        }\n",
    "loadTFLiteModel(path=modelPath, imagePath=imagePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776f4c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 231 modules installed at start\n",
    "import sys, psutil\n",
    "alreadyInstalledList=set([each.split('.')[0] for each in sys.modules.keys()])\n",
    "modul = sys.modules.keys()\n",
    "\n",
    "for idx, item in enumerate(alreadyInstalledList):\n",
    "    if item in sorted(alreadyInstalledList):\n",
    "        # print(f'{idx} {C.BIBlue}{item}{C.ColorOff}')\n",
    "        pass\n",
    "print(f'{idx} modules installed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5591e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tflite_support import flatbuffers\n",
    "from tflite_support import metadata as _metadata\n",
    "from tflite_support import metadata_schema_py_generated as _metadata_fb\n",
    "\n",
    "\"\"\" ... \"\"\"\n",
    "\"\"\"Creates the metadata for an image classifier.\"\"\"\n",
    "\n",
    "# Creates model info.\n",
    "model_meta = _metadata_fb.ModelMetadataT()\n",
    "model_meta.name = \"MobileNetV1 image classifier\"\n",
    "model_meta.description = (\"Identify the most prominent object in the \"\n",
    "                          \"image from a set of 1,001 categories such as \"\n",
    "                          \"trees, animals, food, vehicles, person etc.\")\n",
    "model_meta.version = \"v1\"\n",
    "model_meta.author = \"TensorFlow\"\n",
    "model_meta.license = (\"Apache License. Version 2.0 \"\n",
    "                      \"http://www.apache.org/licenses/LICENSE-2.0.\")\n",
    "\n",
    "model_meta.license"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
