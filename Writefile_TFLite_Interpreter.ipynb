{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcd36f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division\n",
    "from IPython.display import clear_output\n",
    "from BashColors import C\n",
    "from TarfileFunctions import *\n",
    "from CV2_Utils_2 import *\n",
    "\n",
    "import cv2, glob, json, os, sys\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '5'\n",
    "from os.path import *\n",
    "from time import perf_counter, perf_counter_ns\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "contentPath = os.getcwd()\n",
    "genPath = join(contentPath, 'DataGenerator')\n",
    "testPath = join(contentPath, 'images')\n",
    "jsonPath = join(contentPath, 'initialGlobList.json')\n",
    "\n",
    "# modelPath=join(contentPath, 'Defcon4_fp16.tflite')\n",
    "modelPath=join(contentPath, 'Defcon4_mobilenet_v2_Dynamic.tflite')\n",
    "imagePath=join(contentPath, '3b7d7d8a64.jpg')\n",
    "\n",
    "if not exists(genPath):\n",
    "    tff.extractTarfiles('DataGenerator5.tar.gz')\n",
    "if not exists(testPath):\n",
    "    tff.extractTarfiles('images.tar.gz')\n",
    "\n",
    "from time import perf_counter, sleep\n",
    "import concurrent.futures\n",
    "\n",
    "initialGlobList=glob.glob('**')\n",
    "if not 'initialGlobList.json' in initialGlobList:\n",
    "    initialGlobList.append('initialGlobList.json')\n",
    "\n",
    "with open(\"initialGlobList.json\", 'w') as f:\n",
    "    # indent=2 is not needed but makes the file human-readable\n",
    "    json.dump(initialGlobList, f, indent=2)\n",
    "\n",
    "with open(\"initialGlobList.json\", 'r') as f:\n",
    "    initialGlobList = json.load(f)\n",
    "    fileCount=0\n",
    "    for fil in initialGlobList:\n",
    "        fileCount+=1\n",
    "        # print(fil)\n",
    "print(f'{fileCount}{C.BIBlue} files in contentPath')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08884067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the model doesn't have SignatureDefs defined.\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_path=modelPath)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Test the model on random input data.\n",
    "input_shape = input_details[0]['shape']\n",
    "\n",
    "input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\n",
    "print(input_data.shape)\n",
    "image = cv2.imread(imagePath, cv2.IMREAD_COLOR)\n",
    "image = cv2.resize(image, (224, 224))\n",
    "cvu.plotShowSingleImage(image)\n",
    "image = np.ndarray(shape=image.shape).astype(np.float32, copy=True)\n",
    "# image = np.array(image).astype(float32)\n",
    "image = np.expand_dims(image, axis=0)\n",
    "input_data=image\n",
    "\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "interpreter.invoke()\n",
    "\n",
    "# The function `get_tensor()` returns a copy of the tensor data.\n",
    "# Use `tensor()` in order to get a pointer to the tensor.\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffaf27a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c5770d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "\n",
    "modelPath=join(contentPath, 'Defcon4_fp16.tflite')\n",
    "imagePath=join(contentPath, '3b7d7d8a64.jpg')\n",
    "\n",
    "input_details=list()\n",
    "output_details=list()\n",
    "interpreter=None\n",
    "def loadTFLiteModel(path, imagePath, silent=True):\n",
    "    '''Load the model\\npath:Path to tflite model.\\npath to image.'''\n",
    "    interpreter = tf.lite.Interpreter(model_path = modelPath)\n",
    "    interpreter.allocate_tensors()\n",
    "    # Get input and output tensors.\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    # Load image data with dtype=np.uint8\n",
    "    # The input data's shape should match input_details[0]['shape'], which is\n",
    "    # BATCH_SIZE x HEIGHT (224) x WIDTH (224) x CHANNELS (3)\n",
    "    \n",
    "    image = cv2.imread(imagePath, cv2.IMREAD_COLOR)\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    # print(image.shape)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    # print(image.shape)\n",
    "    \n",
    "    interpreter.set_tensor(input_details[0]['index'], image)\n",
    "    interpreter.invoke()\n",
    "    \n",
    "    if not silent:\n",
    "        print(interpreter)\n",
    "        print(type(input_details))\n",
    "        print(input_details, '\\n')\n",
    "        print(type(output_details))\n",
    "        print(output_details)\n",
    "    \n",
    "    return interpreter\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1711c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = loadTFLiteModel(\n",
    "    path=modelPath, imagePath=imagePath, silent=True)\n",
    "\n",
    "inputs=interpreter.get_input_details()\n",
    "print(inputs, '\\n')\n",
    "\n",
    "\n",
    "\n",
    "outputs=interpreter.get_output_details()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee7be94",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputDict={'name': str}\n",
    "outputDict.update()\n",
    "interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9be89d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loadTFLiteModel(path=modelPath, imagePath=imagePath)\n",
    "\n",
    "    # The function `get_tensor()` returns a copy of the tensor data.\n",
    "    # Use `tensor()` in order to get a pointer to the tensor.\n",
    "    output_dict = {\n",
    "        'num_detections': int(interpreter.get_tensor(output_details[3][\"index\"])),\n",
    "        'detection_classes': interpreter.get_tensor(output_details[1][\"index\"]).astype(np.uint8),\n",
    "        'detection_boxes' : interpreter.get_tensor(outputs[0][\"index\"]),\n",
    "        'detection_scores' : interpreter.get_tensor(outputs[2][\"index\"])\n",
    "        }\n",
    "loadTFLiteModel(path=modelPath, imagePath=imagePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776f4c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 231 modules installed at start\n",
    "import sys, psutil\n",
    "alreadyInstalledList=set([each.split('.')[0] for each in sys.modules.keys()])\n",
    "modul = sys.modules.keys()\n",
    "\n",
    "for idx, item in enumerate(alreadyInstalledList):\n",
    "    if item in sorted(alreadyInstalledList):\n",
    "        # print(f'{idx} {C.BIBlue}{item}{C.ColorOff}')\n",
    "        pass\n",
    "print(f'{idx} modules installed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5591e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tflite_support import flatbuffers\n",
    "from tflite_support import metadata as _metadata\n",
    "from tflite_support import metadata_schema_py_generated as _metadata_fb\n",
    "\n",
    "\"\"\" ... \"\"\"\n",
    "\"\"\"Creates the metadata for an image classifier.\"\"\"\n",
    "\n",
    "# Creates model info.\n",
    "model_meta = _metadata_fb.ModelMetadataT()\n",
    "model_meta.name = \"MobileNetV1 image classifier\"\n",
    "model_meta.description = (\"Identify the most prominent object in the \"\n",
    "                          \"image from a set of 1,001 categories such as \"\n",
    "                          \"trees, animals, food, vehicles, person etc.\")\n",
    "model_meta.version = \"v1\"\n",
    "model_meta.author = \"TensorFlow\"\n",
    "model_meta.license = (\"Apache License. Version 2.0 \"\n",
    "                      \"http://www.apache.org/licenses/LICENSE-2.0.\")\n",
    "\n",
    "model_meta.license"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
