{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ada0f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from IPython.display import clear_output\n",
    "import os\n",
    "from os.path import *\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '4'\n",
    "from time import perf_counter\n",
    "from BashColors import C\n",
    "from TarfileFunctions import *\n",
    "from CV2_Utils_2 import *\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "from os.path import exists, join\n",
    "\n",
    "contentPath = os.getcwd()\n",
    "cv2Path=join(contentPath, 'CV2Images')\n",
    "genPath=join(contentPath, 'DataGenerator')\n",
    "testPath=join(contentPath, 'images')\n",
    "checkpointPath = join(contentPath, 'CheckPoints')\n",
    "if not exists(genPath):\n",
    "    tff.extractTarfiles('DataGenerator3.tar.gz')\n",
    "if not exists(testPath):\n",
    "    tff.extractTarfiles('images.tar.gz')\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4896a413",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='loss', min_delta=0, patience=2, verbose=1,\n",
    "    mode='auto', baseline=None, restore_best_weights=True,\n",
    "    # print('\\n',\n",
    ")\n",
    "\n",
    "checkpoints = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath = checkpointPath,\n",
    "    monitor='loss', verbose=1, save_best_only=True,\n",
    "    save_weights_only=False, mode='auto', save_freq='epoch',\n",
    "    options=None\n",
    ")\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90be910c",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE=(224, 224)\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "train_ds = image_dataset_from_directory(\n",
    "    genPath,\n",
    "    color_mode='rgb',\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=456,\n",
    "    image_size=(224, 224),\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE)\n",
    "print()\n",
    "\n",
    "validation_ds = image_dataset_from_directory(\n",
    "    genPath,\n",
    "    color_mode='rgb',\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=456,\n",
    "    image_size=(224, 224),\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE)\n",
    "print()\n",
    "\n",
    "test_ds = image_dataset_from_directory(\n",
    "    testPath,\n",
    "    color_mode='rgb',\n",
    "    image_size=(224, 224),\n",
    "    shuffle=False,\n",
    "    batch_size = 1)\n",
    "# clear_output()\n",
    "\n",
    "TRAIN_STEPS = 676 // BATCH_SIZE\n",
    "print('\\nTRAIN_STEPS:', TRAIN_STEPS)\n",
    "VAL_STEPS =  168 // BATCH_SIZE\n",
    "print('VAL_STEPS:', VAL_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e2ac0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential(name='Defcon4_Sequential_V8')\n",
    "model.add(Conv2D(\n",
    "    32, (3,3), activation='relu', input_shape=(224,224,3)))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "\n",
    "model.add(Conv2D(128, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "model.add(Conv2D(256, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "model.add(Conv2D(512, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu')) # hidden layer\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.build()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76273028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_rate=0.001, rho=0.9, momentum=0.0, epsilon=1e-07, centered=False\n",
    "myOptimizer = tf.keras.optimizers.RMSprop(\n",
    "    learning_rate=0.005, rho=0.9, momentum=0.0, epsilon=1e-07,\n",
    "    centered=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f75fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer = myOptimizer,\n",
    "              metrics=['accuracy'])\n",
    "model.built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69961174",
   "metadata": {},
   "outputs": [],
   "source": [
    "startTimer=perf_counter()\n",
    "history  =  model.fit(\n",
    "    x = train_ds,\n",
    "    y = None,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    epochs = 2,\n",
    "    verbose = 'auto',\n",
    "    callbacks = [earlyStop, checkpoints],\n",
    "    validation_split = 0.0,\n",
    "    validation_data = validation_ds,\n",
    "    shuffle = False,\n",
    "    class_weight = None,\n",
    "    sample_weight = None,\n",
    "    initial_epoch = 0,\n",
    "    steps_per_epoch = TRAIN_STEPS,\n",
    "    validation_steps = VAL_STEPS,\n",
    "    validation_batch_size = BATCH_SIZE,\n",
    "    validation_freq = 1,\n",
    "    max_queue_size = 4,\n",
    "    workers = 2,\n",
    "    use_multiprocessing = True,\n",
    ")\n",
    "finishTimer=perf_counter()\n",
    "cvu.printTime(startTimer, finishTimer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6a4a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = model.name + '_dnn.h5'\n",
    "modelSavePath = join(contentPath, modelName)\n",
    "print(f'model saved to: {modelSavePath}')\n",
    "model.save(modelSavePath, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537a6d9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121ad1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "newModelName = model.name + '.tflite'\n",
    "# modelSavePath = join(contentPath, modelName)\n",
    "print(f'newModelName: {C.BIPurple}{newModelName}{C.ColorOff}')\n",
    "\n",
    "# Convert the model\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(checkpointPath) # path to the SavedModel directory\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open(newModelName, 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "if exists(newModelName):\n",
    "    print(f'saved: {C.BIGreen}{newModelName}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f92fb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls -l"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
